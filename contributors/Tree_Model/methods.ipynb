{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Machine Learning Methods and Tools\n",
    "\n",
    "Explain the method and why you think it's suitable for your use case. Explain the choice of tools/packages/data and the reason for use.\n",
    "\n",
    "Addressing a key gap in the application of ML for SWE estimation, we introduce a novel two-step ML framework combining gradient boosted decision trees with feature optimization for the selection of training features to inform regionally optimized ANNs.\n",
    "With a motivation to enhance SWE characterization targeting large-scale water resources management, we validate the framework by evaluating the performance of SWE estimates for 20,000 locations across the western U.S. at a 1-km scale and weekly temporal resolution.\n",
    "This sections explains the methodology for developing the national-scale SWE estimation model and dives deeper into the case application in the Colorodo region that this tutorial executes. \n",
    "\n",
    "## Study Area Description\n",
    "\n",
    "Model developmnet leverage data from SNOTEL sites located throughout 11 states ranging from the US-Canada border to the US-Mexico border and from the Pacific coast to the eastern slope of the Rocky Mountains to establish the study periphery.\n",
    "The modeling domain includes all major mountain ranges but contains a greater portion of observations within the Sierra Nevada and the Rocky Mountains, where the water supply is dominated by seasonal snowpack and ongoing efforts by the Airborne Snow Observatory (ASO) provide ample data for data-driven model development.\n",
    "\n",
    "\n",
    "## Machine Learning Approach\n",
    "\n",
    "Snow falls different accross the western US, and thus, was decided upon to develop a distributed ML SWE estimation model addressing the unique hydrometeorological variability observed in the modeling doamain.\n",
    "For example, the western U.S. contains snow climate classifications of coastal, coastal transitional, intermountain, and continental.\n",
    "The modeling framework addresses the heterogeneity in snow processes through the the division of the study area into 23 regional locations. \n",
    "Dividing the model into sub-regions allows for the separation of microclimates to reduce the influence of individual region dynamics on differing regions during model training. \n",
    "\n",
    "<img align = 'center' src=\"./Images/Distribution.jpg\" alt = 'drawing' width = '1000'/>\n",
    "\n",
    "## Data\n",
    "Machine learning models \"learn\" the relationships between independent and dependent variables through large amounts of data.\n",
    "Data sourced for the model consisted of geographic and topographic information from the Copernicus Digital Elevation Model (90-m DEM) and ground measurement data from the NRCS Snow Telemetry and Snow Course program (i.e., SNOTEL), as well as from the California Department of Water Resources California Data Exchange Center (CDEC). \n",
    "In total, geographic and weekly SWE observational data from 594 SNOTEL sites and 106 CDEC sites from 2013-2017 are collated.\n",
    "Weekly observations of the most recent date available at the same locations support near-real-time model inference. \n",
    "\n",
    "Model development investigated the use of climatological data from the National Oceanic and Atmospheric Administration's (NOAA) High-Resolution Rapid Refresh dataset (HRRR) and multispectral imagery from the Sentinal-1 remote sensing satellite mission. \n",
    "However, the large computational resources required to load and process the data became limiting to the production of expeditious SWE estimates at scale.\n",
    "The limitations were the result of the large-memory tiled datasets and the need for point-scale architecture required by the ML models to train, test, and predict.\n",
    "The data processing requirements to convert observations into training datasets are computationally expensive and unfeasible for fast-paced development, even for high-performance computing. \n",
    "\n",
    "<img align = 'center' src=\"Images/Distribution_locations_number.jpg\" alt = 'drawing' width = '1000'/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoWeaver\n",
    "\n",
    "\n",
    "The model has been adapted to the open-source workflow management sytem, [GeoWeaver](https://github.com/ESIPFed/Geoweaver). Geoweaver is a web-based application for interactive, full-stack machine leanring workflow management. The app provdies a user-friendly GUI to interact with and persistently store script logs and code revision histories. Shell and python scripts are supported by the platform, as well as seammless intergration wth Jupyter. \n",
    "\n",
    "A detailed overview of the use of the model within Geoweaver is provided in  Chapter 7. [Workflow Management and Cloud Computing](./workflow.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "<img align = 'center' src=\"./Images/GeoWeaver.JPG\" alt = 'drawing' width = '500'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models\n",
    "There are many different types of machine learning models for differnt applications, such as classification, regression, and clustering.\n",
    "For the application of predicting 1-km gridded SWE, a regression model is the best approach.\n",
    "While there are many regression-based machine learning algorithms, we use [Light Gradient Boosted Models (LightGBM)](https://lightgbm.readthedocs.io/en/v3.3.2/) and [Multi-Layered Perceptron networks (MLP)](https://www.tensorflow.org/tutorials/keras/regression).\n",
    "Below is a brief description of each machine learning modeling methodlogy.\n",
    "\n",
    "\n",
    "### LightGBM\n",
    "Gradient boosted decision trees (GBDT) are a machine learning algorithm exhibiting impressive performance across various classification and regression applications.\n",
    "The algorithm generates a solution based on an ensemble of learning models, where weak learner trees, trained on the residuals of an initial strong learner, are iteratively added to the model to minimize the overall loss function (negative root-mean-squared-error) of the model via gradient descent of the individual weak learners. \n",
    "\n",
    "The LightGBM framework is an evolution of GBDT, and introduces Gradient-based One-Side Sampling (GOSS) to the boosting algorithm. \n",
    "GOSS focuses the model learning on trees with larger gradients and randomly drops learners with small gradients to provide a more efficient and more accurate gain estimation than with traditional gradient boosting. \n",
    "\n",
    "### MLP\n",
    "The MLP is a classical type of feedforward ANN, being successfully and frequently applied in environmental modeling applications.\n",
    "The MLP regression model estimates a target variable by learning a non-linear function to describe the target from an input vector of features.\n",
    "It performs learning via a back-propagation algorithm over a series of hidden layers containing interconnected nodes (neurons). \n",
    "The neurons connect bordering layers by a summation of weights and an activation function transforms model outputs to predicted values. \n",
    "The model calculates error and adjusts the weights to minimize the error during model training, supporting the use of \n",
    "MLPs to effectively describe a target variable with any function, continuous or discontinuous. \n",
    "\n",
    "\n",
    "\n",
    "## Dependencies (versions, environments)\n",
    "The modeling framework was built using Python Version 3.8.\n",
    "Below is a url-linked list of the required packages needed to process the data, train the model, process results, and visualize the model outputs.\n",
    "Please take the time to review each package to understand its contribution in the machine learning pipeline.\n",
    "\n",
    "| [os](https://docs.python.org/3/library/os.html)| [ulmo](https://ulmo.readthedocs.io/en/latest/)       | [pandas](https://pandas.pydata.org/)             |[io](https://docs.python.org/3/library/io.html)           | [shapely](https://pypi.org/project/shapely/)    | [datetime](https://docs.python.org/3/library/datetime.html)           |\n",
    "|:-----------: | :--------: | :----------------: | :-----------: | :--------: | :----------------: |\n",
    "| [re](https://docs.python.org/3/library/re.html) | [rasterio](https://pypi.org/project/rasterio/)   | [matplot.pyplot](https://pypi.org/project/matplotlib/)     | [copy](https://docs.python.org/3/library/copy.html)         | [lightgbm](https://lightgbm.readthedocs.io/en/latest/Python-Intro.html)   |  [numpy](https://numpy.org/)             |\n",
    "| [time](https://docs.python.org/3/library/time.html)         | [tensorflow](https://www.tensorflow.org/) |  [pystac_client](https://pystac-client.readthedocs.io/en/stable/)     | [tables](https://pypi.org/project/tables/) | [platfrom](https://docs.python.org/3/library/platform.html)   | [planetary_computer](https://pypi.org/project/planetary-computer/) |\n",
    "| [xarray](https://pypi.org/project/xarray/)| [tqdm](https://pypi.org/project/tqdm/)       | [random](https://docs.python.org/3/library/random.html)             | [rioxarray](https://pypi.org/project/rioxarray/)    | [geopandas](https://geopandas.org/en/stable/getting_started/install.html)  | [requests](https://pypi.org/project/requests/) |\n",
    "| [pyproj](https://pypi.org/project/pyproj/)       | [richdem](https://richdem.readthedocs.io/en/latest/)    | [cartopy](https://scitools.org.uk/cartopy/docs/latest/installing.html)            | [h5py](https://www.h5py.org/)         | [elevation](https://pypi.org/project/elevation/)  | [cmocean](https://pypi.org/project/cmocean/)            |\n",
    "| [mpl_toolkits](https://matplotlib.org/2.2.2/mpl_toolkits/index.html) | [hdfdict](https://pypi.org/project/hdfdict/)    | [warning](https://docs.python.org/3/library/warnings.html)            | [math](https://docs.python.org/3/library/math.html)         | [pickle](https://docs.python.org/3/library/pickle.html)     |  [contextily](https://contextily.readthedocs.io/en/latest/)        |\n",
    "|[folium](https://pypi.org/project/folium/)        | [branca](https://pypi.org/project/branca/)     |  [earthpy](https://earthpy.readthedocs.io/en/latest/)           |[netCDF4](https://pypi.org/project/netCDF4/)       | [osgeo](https://pypi.org/project/osgeo/)      | [webbrowser](https://docs.python.org/3/library/webbrowser.html)          |\n",
    "| [geojson](https://pypi.org/project/geojson/)    | [fiona](https://pypi.org/project/Fiona/)              |    |  |                    | |\n",
    "\n",
    "\n",
    "Now that we have a general understanding of the model framework, lets dig into a model example for the Sierra Nevada region.\n",
    "[Model Development](./training.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c446eef832ec964573dc49f36fd16bdbed40cbfbefbf557bc2dc78d9e7968689"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
